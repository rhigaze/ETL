version: '3'

services:
  etl_pipeline:
    build: .
    container_name: etl_pipeline
    environment:
      - PROJECT_STUDY_COHORT_CSV=data/project_study_cohort.csv
      - SAMPLE_RESULT_CSV=data/sample_run_results.csv
      - SUBJECT_SAMPLE_CSV=data/subject_samples.csv
  webserver:
    image: apache/airflow:2.3.0
    environment:
      AIRFLOW__CORE__EXECUTOR: SequentialExecutor
      AIRFLOW__CORE__FERNET_KEY: ""
      AIRFLOW__WEBSERVER__RBAC: "True"
      AIRFLOW__CORE__LOAD_EXAMPLES: "False"
    volumes:
      - ./dags:/opt/airflow/dags
      - ./logs:/opt/airflow/logs
      - /var/run/docker.sock:/var/run/docker.s
    ports:
      - "8080:8080"
    command: >
      bash -c "
      airflow db init &&
      airflow users create --username admin --password admin --firstname admin --lastname admin --role Admin --email admin@example.com &&
      airflow webserver & airflow scheduler
      "
